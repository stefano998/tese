{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "be615d20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8343,
     "status": "ok",
     "timestamp": 1652121200019,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "be615d20",
    "outputId": "8edf2c02-5f1b-492a-b52a-ca522ea95fc0"
   },
   "outputs": [],
   "source": [
    "#importa bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3f3d8027",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2095,
     "status": "ok",
     "timestamp": 1652121202108,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "3f3d8027",
    "outputId": "0b5391b9-8567-48f5-d93c-f5a27bdd9439"
   },
   "outputs": [],
   "source": [
    "#preencher nome da rede geodesica analisada (abaixo os nomes das redes A, B, C, D, E e F, respectivamente)\n",
    "#alias opcoes = {'gemael147','ghi355gps','nive20obs','gnssrbc21','ghiniv255','kleincorr'}\n",
    "alias='kleincorr'\n",
    "aux_filename_36_train=\"_0-2outs_3-6s_50000itr_train\"\n",
    "aux_filename_69_train=\"_0-2outs_6-9s_50000itr_train\"\n",
    "aux_filename_36=\"_0out200000_1-2outs_3-6s_50000itr\"\n",
    "aux_filename_69=\"_0out200000_1-2outs_6-9s_50000itr\"\n",
    "\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#caminho=\"/content/drive/MyDrive/Colab_data/\"+alias+\"/\"+alias+\"_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c37de329",
   "metadata": {
    "executionInfo": {
     "elapsed": 136310,
     "status": "ok",
     "timestamp": 1652121338414,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "c37de329"
   },
   "outputs": [],
   "source": [
    "#importa arquivos para treinamento e validação\n",
    "caminho=\"C:/Users/Patricia/Desktop/IP3new/00.treino_rna/\"+alias+\"_\" \n",
    "A = np.loadtxt(caminho+\"A\")\n",
    "m = A.shape[0]\n",
    "qtt_exs = m*150000\n",
    "\n",
    "wAllEL1_pi_sigma_v_36_train = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "ypredEL1_pi_sigma_v_36_train = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "wAllELInf_pp_sig_obs_36_train = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "ypredELInf_pp_sig_obs_36_train = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "wAllELInf_pi_sig_obs_36_train = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "ypredELInf_pi_sig_obs_36_train = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "wAllIDS_pp_36_train = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "ypredIDS_pp_36_train = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "wAllSLRTMO_pp_36_train = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "ypredSLRTMO_pp_36_train = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "outs_positions_36_train = np.loadtxt(caminho+\"outs_positions\"+aux_filename_36_train).reshape(qtt_exs,1)\n",
    "\n",
    "wAllEL1_pi_sigma_v_69_train = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "ypredEL1_pi_sigma_v_69_train = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "wAllELInf_pp_sig_obs_69_train = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "ypredELInf_pp_sig_obs_69_train = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "wAllELInf_pi_sig_obs_69_train = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "ypredELInf_pi_sig_obs_69_train = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "wAllIDS_pp_69_train = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "ypredIDS_pp_69_train = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "wAllSLRTMO_pp_69_train = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "ypredSLRTMO_pp_69_train = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "outs_positions_69_train = np.loadtxt(caminho+\"outs_positions\"+aux_filename_69_train).reshape(qtt_exs,1)\n",
    "\n",
    "diag_redund_train = np.loadtxt(caminho+\"diag_da_matriz_redund\")\n",
    "diag_redund_train = (np.ones((int(qtt_exs/m),diag_redund_train.shape[0]))*diag_redund_train).reshape(qtt_exs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e9e2436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa arquivos para matriz Ev e testes do metaclassificador\n",
    "caminho=\"C:/Users/Patricia/Desktop/IP3new/\"+alias+\"_\" \n",
    "qtt_exs = m*300000\n",
    "\n",
    "wAllEL1_pi_sigma_v_36 = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "ypredEL1_pi_sigma_v_36 = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "wAllELInf_pp_sig_obs_36 = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "ypredELInf_pp_sig_obs_36 = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "wAllELInf_pi_sig_obs_36 = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "ypredELInf_pi_sig_obs_36 = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "wAllIDS_pp_36 = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "ypredIDS_pp_36 = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "wAllSLRTMO_pp_36 = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "ypredSLRTMO_pp_36 = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "outs_positions_36 = np.loadtxt(caminho+\"outs_positions\"+aux_filename_36).reshape(qtt_exs,1)\n",
    "\n",
    "wAllEL1_pi_sigma_v_69 = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "ypredEL1_pi_sigma_v_69 = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "wAllELInf_pp_sig_obs_69 = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "ypredELInf_pp_sig_obs_69 = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "wAllELInf_pi_sig_obs_69 = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "ypredELInf_pi_sig_obs_69 = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "wAllIDS_pp_69 = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "ypredIDS_pp_69 = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "wAllSLRTMO_pp_69 = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "ypredSLRTMO_pp_69 = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "outs_positions_69 = np.loadtxt(caminho+\"outs_positions\"+aux_filename_69).reshape(qtt_exs,1)\n",
    "\n",
    "diag_redund = np.loadtxt(caminho+\"diag_da_matriz_redund\")\n",
    "diag_redund = (np.ones((int(qtt_exs/m),diag_redund.shape[0]))*diag_redund).reshape(qtt_exs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "66173246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1652121338793,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "66173246",
    "outputId": "60f1f792-f77f-4ed4-c3dd-dab21b7a1aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4875000, 11) (5850000,) (11700000, 11) (11700000, 1) (7800000, 11) (200000, 39)\n"
     ]
    }
   ],
   "source": [
    "#forma conjuntos de treino, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5xm, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma);\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train,\n",
    "             ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train,\n",
    "             ypredELInf_pi_sig_obs_36_train,wAllELInf_pi_sig_obs_36_train,ypredELInf_pp_sig_obs_36_train,wAllELInf_pp_sig_obs_36_train,\n",
    "             ypredSLRTMO_pp_36_train,wAllSLRTMO_pp_36_train,\n",
    "              diag_redund_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train,\n",
    "             ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train,\n",
    "             ypredELInf_pi_sig_obs_69_train,wAllELInf_pi_sig_obs_69_train,ypredELInf_pp_sig_obs_69_train,wAllELInf_pp_sig_obs_69_train,\n",
    "             ypredSLRTMO_pp_69_train,wAllSLRTMO_pp_69_train,\n",
    "              diag_redund_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36,\n",
    "             ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36,\n",
    "             ypredELInf_pi_sig_obs_36,wAllELInf_pi_sig_obs_36,ypredELInf_pp_sig_obs_36,wAllELInf_pp_sig_obs_36,\n",
    "             ypredSLRTMO_pp_36,wAllSLRTMO_pp_36,\n",
    "             diag_redund)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69,\n",
    "             ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69,\n",
    "             ypredELInf_pi_sig_obs_69,wAllELInf_pi_sig_obs_69,ypredELInf_pp_sig_obs_69,wAllELInf_pp_sig_obs_69,\n",
    "             ypredSLRTMO_pp_69,wAllSLRTMO_pp_69,\n",
    "             diag_redund)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux = int(y_test36.shape[0]/m)\n",
    "y_Ev = np.reshape(y_test36, (aux, m), order='C')\n",
    "X_Ev = np.reshape(X_test36, (aux, 11*m), order='C')\n",
    "aux=sum(np.transpose(y_Ev))==0        ##### era y_test (usando o \"local\" da fç..)\n",
    "X_Ev = X_Ev[aux,:]\n",
    "y_Ev = y_Ev[aux,:]\n",
    "aux = int(X_Ev.shape[0]*m)\n",
    "X_Ev = np.reshape(X_Ev, (aux, 11), order='C')\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+m*qtd_graphs,:],obs_36_train[m*50000:m*50000+m*qtd_graphs,:],\n",
    "                         obs_36_train[m*100000:m*100000+int(m*qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+m*qtd_graphs,:],label_36_train[m*50000:m*50000+m*qtd_graphs,:],\n",
    "                         label_36_train[m*100000:m*100000+int(m*qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[m*50000:m*50000+m*qtd_graphs,:],\n",
    "                         obs_69_train[m*100000:m*100000+int(m*qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[m*50000:m*50000+m*qtd_graphs,:],\n",
    "                         label_69_train[m*100000:m*100000+int(m*qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[m*25000:m*50000,:],obs_36_train[m*75000:m*100000,:],obs_36_train[m*125000:m*150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[m*25000:m*50000,:],obs_69_train[m*75000:m*100000,:],obs_69_train[m*125000:m*150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[m*25000:m*50000,:],label_36_train[m*75000:m*100000,:],label_36_train[m*125000:m*150000,:]),axis=0).flatten('C')\n",
    "y_val69 = np.concatenate((label_69_train[m*25000:m*50000,:],label_69_train[m*75000:m*100000,:],label_69_train[m*125000:m*150000,:]),axis=0).flatten('C')\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(m*qtd_graphs*VS),:],\n",
    "                          X_train36[int(m*qtd_graphs*1):int(m*qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(m*qtd_graphs*2):int(m*qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(m*qtd_graphs*VS),:],\n",
    "                          X_train69[int(m*qtd_graphs*1):int(m*qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(m*qtd_graphs*VS):int(m*qtd_graphs*1),:],\n",
    "                          X_train36[int(m*qtd_graphs*(1+VS)):int(m*qtd_graphs*2),:],\n",
    "                          X_train36[int(m*qtd_graphs*(2+VS)):int(m*qtd_graphs*3),:],\n",
    "                          X_train69[int(m*qtd_graphs*VS):int(m*qtd_graphs*1),:],\n",
    "                          X_train69[int(m*qtd_graphs*(1+VS)):int(m*qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(m*qtd_graphs*VS),:],\n",
    "                          y_train36[int(m*qtd_graphs*1):int(m*qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(m*qtd_graphs*2):int(m*qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(m*qtd_graphs*VS),:],\n",
    "                          y_train69[int(m*qtd_graphs*1):int(m*qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(m*qtd_graphs*VS):int(m*qtd_graphs*1),:],\n",
    "                          y_train36[int(m*qtd_graphs*(1+VS)):int(m*qtd_graphs*2),:],\n",
    "                          y_train36[int(m*qtd_graphs*(2+VS)):int(m*qtd_graphs*3),:],\n",
    "                          y_train69[int(m*qtd_graphs*VS):int(m*qtd_graphs*1),:],\n",
    "                          y_train69[int(m*qtd_graphs*(1+VS)):int(m*qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() \n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0).flatten('C')\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0).flatten('C')\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c11b96ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1652123151086,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "c11b96ea"
   },
   "outputs": [],
   "source": [
    "#funcao para avaliar desempenho do metaclassificador\n",
    "def clf_eval(y_pred, y_val):\n",
    "  if y_pred.ndim < 2 : ## isso eh apenas para o caso de granularidade nas obs..\n",
    "    aux = int(y_pred.shape[0]/m)\n",
    "    y_pred = np.reshape(y_pred, (aux, m), order='C')\n",
    "    y_val = np.reshape(y_val, (aux, m), order='C')\n",
    "  acc = 100*accuracy_score(y_pred, y_val)\n",
    "  print('Accuracy: {}'.format(acc))\n",
    "  #acurácia somente para conjunto que tenha 2 outliers \n",
    "  aux=sum(np.transpose(y_val))==2\n",
    "  acc2=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "  print('Accuracy 2 out: {}'.format(acc2))\n",
    "  #acurácia somente para conjunto que tenha 1 outliers \n",
    "  aux=sum(np.transpose(y_val))==1\n",
    "  acc1=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "  print('Accuracy 1 out: {}'.format(acc1))\n",
    "  #acurácia somente para conjunto que tenha 0 outliers \n",
    "  aux=sum(np.transpose(y_val))==0\n",
    "  acc0=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "  print('Accuracy 0 out: {}'.format(acc0))\n",
    "  acc = (acc2+acc1)/2\n",
    "  #print('Accuracy: {}'.format(acc))\n",
    "  acc = [acc, acc1, acc2]\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "512c463c",
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1652122265734,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "512c463c"
   },
   "outputs": [],
   "source": [
    "#funcao para controle da taxa de falsos positivos do metaclassificador\n",
    "def fp_control(FP, X_test, y_test):\n",
    "\n",
    "  probs = np.array(model.predict(X_Ev,batch_size=200*m))\n",
    "  aux = y_Ev.shape[0]\n",
    "  #aux = int(y_test.shape[0]/m)\n",
    "  #y_test_aux = np.reshape(y_test, (aux, m), order='C')\n",
    "  probs = np.reshape(probs, (aux, m), order='C')\n",
    "  #aux=sum(np.transpose(y_test_aux))==0\n",
    "  #maxs = np.sort(np.amax(probs[aux,:], axis=1))\n",
    "  maxs = np.sort(np.amax(probs, axis=1))\n",
    "  position = int((1-FP)*maxs.shape[0])\n",
    "  threshold = maxs[position]\n",
    "\n",
    "  probs = np.array(model.predict(X_test))\n",
    "  preds = (np.where(probs[:,:] > threshold, 1, 0))\n",
    "  #print(preds.shape)\n",
    "  if y_test.ndim < 2 : ## isso eh apenas para o caso de granularidade nas obs..\n",
    "    preds = preds[:,0]\n",
    "  #print(preds.shape)\n",
    "  label = y_test\n",
    "  #print(label.shape)\n",
    "  acc =clf_eval(preds,label)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0ac42148",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao:\n",
      "Accuracy: 82.80133333333333\n",
      "Accuracy 2 out: 69.1\n",
      "Accuracy 1 out: 84.416\n",
      "Accuracy 0 out: 94.88799999999999\n",
      "Accuracy: 93.55466666666666\n",
      "Accuracy 2 out: 90.608\n",
      "Accuracy 1 out: 95.16799999999999\n",
      "Accuracy 0 out: 94.88799999999999\n",
      "MSR: 84.823\n"
     ]
    }
   ],
   "source": [
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32*m,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "clf=model\n",
    "print(\"Validacao:\") \n",
    "acc36 = fp_control(0.05, X_val36, y_val36) \n",
    "acc69 = fp_control(0.05, X_val69, y_val69) \n",
    "print(\"MSR:\", (acc36[1] + acc36[2] + acc69[1] + acc69[2])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "aa1c146d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao:\n",
      "Accuracy: 82.83066666666666\n",
      "Accuracy 2 out: 68.892\n",
      "Accuracy 1 out: 84.708\n",
      "Accuracy 0 out: 94.892\n",
      "Accuracy: 94.268\n",
      "Accuracy 2 out: 92.052\n",
      "Accuracy 1 out: 95.86\n",
      "Accuracy 0 out: 94.892\n",
      "MSR: 85.378\n"
     ]
    }
   ],
   "source": [
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32*m,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "clf=model\n",
    "print(\"Validacao:\") \n",
    "acc36 = fp_control(0.05, X_val36, y_val36) \n",
    "acc69 = fp_control(0.05, X_val69, y_val69) \n",
    "print(\"MSR:\", (acc36[1] + acc36[2] + acc69[1] + acc69[2])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4d42aa98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao:\n",
      "Accuracy: 82.50800000000001\n",
      "Accuracy 2 out: 68.56400000000001\n",
      "Accuracy 1 out: 84.072\n",
      "Accuracy 0 out: 94.88799999999999\n",
      "Accuracy: 93.524\n",
      "Accuracy 2 out: 90.64\n",
      "Accuracy 1 out: 95.044\n",
      "Accuracy 0 out: 94.88799999999999\n",
      "MSR: 84.58\n"
     ]
    }
   ],
   "source": [
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/2))\n",
    "hidden3 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(hidden3, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32*m,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "clf=model\n",
    "print(\"Validacao:\") \n",
    "acc36 = fp_control(0.05, X_val36, y_val36) \n",
    "acc69 = fp_control(0.05, X_val69, y_val69) \n",
    "print(\"MSR:\", (acc36[1] + acc36[2] + acc69[1] + acc69[2])/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d94d9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validacao:\n",
      "Accuracy: 82.72\n",
      "Accuracy 2 out: 68.928\n",
      "Accuracy 1 out: 84.336\n",
      "Accuracy 0 out: 94.896\n",
      "Accuracy: 94.028\n",
      "Accuracy 2 out: 91.792\n",
      "Accuracy 1 out: 95.396\n",
      "Accuracy 0 out: 94.896\n",
      "MSR: 85.113\n"
     ]
    }
   ],
   "source": [
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/2))\n",
    "hidden3 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(hidden3, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=1, activation='sigmoid'))  \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.01), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32*m,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "clf=model\n",
    "print(\"Validacao:\") \n",
    "acc36 = fp_control(0.05, X_val36, y_val36) \n",
    "acc69 = fp_control(0.05, X_val69, y_val69) \n",
    "print(\"MSR:\", (acc36[1] + acc36[2] + acc69[1] + acc69[2])/4)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "keras_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
