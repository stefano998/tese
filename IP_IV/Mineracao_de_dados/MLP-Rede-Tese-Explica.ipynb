{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be615d20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8343,
     "status": "ok",
     "timestamp": 1652121200019,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "be615d20",
    "outputId": "8edf2c02-5f1b-492a-b52a-ca522ea95fc0"
   },
   "outputs": [],
   "source": [
    "#importa bibliotecas\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f3d8027",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2095,
     "status": "ok",
     "timestamp": 1652121202108,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "3f3d8027",
    "outputId": "0b5391b9-8567-48f5-d93c-f5a27bdd9439"
   },
   "outputs": [],
   "source": [
    "#preencher nome da rede geodesica analisada (abaixo os nomes das redes A, B, C, D, E e F, respectivamente)\n",
    "#alias opcoes = {'gemael147','ghi355gps','nive20obs','gnssrbc21','ghiniv255','kleincorr'}\n",
    "alias='ghi355gps'\n",
    "aux_filename_36_train=\"_0-2outs_3-6s_50000itr_train\"\n",
    "aux_filename_69_train=\"_0-2outs_6-9s_50000itr_train\"\n",
    "aux_filename_36=\"_0out200000_1-2outs_3-6s_50000itr\"\n",
    "aux_filename_69=\"_0out200000_1-2outs_6-9s_50000itr\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c37de329",
   "metadata": {
    "executionInfo": {
     "elapsed": 136310,
     "status": "ok",
     "timestamp": 1652121338414,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "c37de329"
   },
   "outputs": [],
   "source": [
    "#importa arquivos para treinamento do metaclassificador\n",
    "caminho=\"C:/Users/Patricia/Desktop/IP3new/00.treino_rna/\"+alias+\"_\" #importa arquivos para treinamento do metaclassificador\n",
    "\n",
    "wAllEL1_pi_sigma_v_36_train = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_36_train)\n",
    "ypredEL1_pi_sigma_v_36_train = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_36_train)\n",
    "wAllELInf_pp_sig_obs_36_train = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_36_train)\n",
    "ypredELInf_pp_sig_obs_36_train = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_36_train)\n",
    "wAllELInf_pi_sig_obs_36_train = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_36_train)\n",
    "ypredELInf_pi_sig_obs_36_train = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_36_train)\n",
    "wAllIDS_pp_36_train = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_36_train)\n",
    "ypredIDS_pp_36_train = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_36_train)\n",
    "wAllSLRTMO_pp_36_train = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_36_train)\n",
    "ypredSLRTMO_pp_36_train = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_36_train)\n",
    "outs_positions_36_train = np.loadtxt(caminho+\"outs_positions\"+aux_filename_36_train)\n",
    "\n",
    "wAllEL1_pi_sigma_v_69_train = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_69_train)\n",
    "ypredEL1_pi_sigma_v_69_train = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_69_train)\n",
    "wAllELInf_pp_sig_obs_69_train = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_69_train)\n",
    "ypredELInf_pp_sig_obs_69_train = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_69_train)\n",
    "wAllELInf_pi_sig_obs_69_train = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_69_train)\n",
    "ypredELInf_pi_sig_obs_69_train = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_69_train)\n",
    "wAllIDS_pp_69_train = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_69_train)\n",
    "ypredIDS_pp_69_train = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_69_train)\n",
    "wAllSLRTMO_pp_69_train = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_69_train)\n",
    "ypredSLRTMO_pp_69_train = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_69_train)\n",
    "outs_positions_69_train = np.loadtxt(caminho+\"outs_positions\"+aux_filename_69_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5e84464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importa arquivos para matriz Ev e testes do metaclassificador\n",
    "caminho=\"C:/Users/Patricia/Desktop/IP3new/\"+alias+\"_\" \n",
    "\n",
    "wAllEL1_pi_sigma_v_36 = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_36)\n",
    "ypredEL1_pi_sigma_v_36 = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_36)\n",
    "wAllELInf_pp_sig_obs_36 = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_36)\n",
    "ypredELInf_pp_sig_obs_36 = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_36)\n",
    "wAllELInf_pi_sig_obs_36 = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_36)\n",
    "ypredELInf_pi_sig_obs_36 = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_36)\n",
    "wAllIDS_pp_36 = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_36)\n",
    "ypredIDS_pp_36 = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_36)\n",
    "wAllSLRTMO_pp_36 = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_36)\n",
    "ypredSLRTMO_pp_36 = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_36)\n",
    "outs_positions_36 = np.loadtxt(caminho+\"outs_positions\"+aux_filename_36)\n",
    "\n",
    "wAllEL1_pi_sigma_v_69 = np.loadtxt(caminho+\"wAllEL1_pi_sigma_v\"+aux_filename_69)\n",
    "ypredEL1_pi_sigma_v_69 = np.loadtxt(caminho+\"ypredEL1_pi_sigma_v\"+aux_filename_69)\n",
    "wAllELInf_pp_sig_obs_69 = np.loadtxt(caminho+\"wAllELInf_pp_sig_obs\"+aux_filename_69)\n",
    "ypredELInf_pp_sig_obs_69 = np.loadtxt(caminho+\"ypredELInf_pp_sig_obs\"+aux_filename_69)\n",
    "wAllELInf_pi_sig_obs_69 = np.loadtxt(caminho+\"wAllELInf_pi_sig_obs\"+aux_filename_69)\n",
    "ypredELInf_pi_sig_obs_69 = np.loadtxt(caminho+\"ypredELInf_pi_sig_obs\"+aux_filename_69)\n",
    "wAllIDS_pp_69 = np.loadtxt(caminho+\"wAllIDS_pp\"+aux_filename_69)\n",
    "ypredIDS_pp_69 = np.loadtxt(caminho+\"ypredIDS_pp\"+aux_filename_69)\n",
    "wAllSLRTMO_pp_69 = np.loadtxt(caminho+\"wAllSLRTMO_pp\"+aux_filename_69)\n",
    "ypredSLRTMO_pp_69 = np.loadtxt(caminho+\"ypredSLRTMO_pp\"+aux_filename_69)\n",
    "outs_positions_69 = np.loadtxt(caminho+\"outs_positions\"+aux_filename_69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c11b96ea",
   "metadata": {
    "executionInfo": {
     "elapsed": 249,
     "status": "ok",
     "timestamp": 1652123151086,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "c11b96ea"
   },
   "outputs": [],
   "source": [
    "#funcao para avaliar desempenho do metaclassificador\n",
    "def clf_eval(y_pred, y_val):\n",
    "  acc = 100*accuracy_score(y_pred, y_val)\n",
    "  print('Accuracy: {}'.format(acc))\n",
    "  #acurácia somente para conjunto que tenha 3 outliers \n",
    "  if out3 == 1:\n",
    "      aux=sum(np.transpose(y_val))==3\n",
    "      acc3=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "      print('Accuracy 3 out: {}'.format(acc3))\n",
    "  #acurácia somente para conjunto que tenha 2 outliers \n",
    "  else:\n",
    "      aux=sum(np.transpose(y_val))==2\n",
    "      acc2=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "      print('Accuracy 2 out: {}'.format(acc2))\n",
    "  #acurácia somente para conjunto que tenha 1 outliers \n",
    "      aux=sum(np.transpose(y_val))==1\n",
    "      acc1=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "      print('Accuracy 1 out: {}'.format(acc1))\n",
    "  #acurácia somente para conjunto que tenha 0 outliers \n",
    "  aux=sum(np.transpose(y_val))==0\n",
    "  acc0=100*accuracy_score(y_val[aux,:], y_pred[aux,:])\n",
    "  print('Accuracy 0 out: {}'.format(acc0))\n",
    "  if out3 == 0:\n",
    "    return [acc1, acc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "512c463c",
   "metadata": {
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1652122265734,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "512c463c"
   },
   "outputs": [],
   "source": [
    "#funcao para controle da taxa de falsos positivos do metaclassificador\n",
    "def fp_control(model,FP, X_test, y_test):\n",
    "  probs = np.array(model.predict(X_Ev))   ### era X_test (usando o \"local\" da fç..)\n",
    "  maxs = np.sort(np.amax(probs, axis=1))\n",
    "  position = int((1-FP)*maxs.shape[0])\n",
    "  threshold = maxs[position]\n",
    "\n",
    "  probs = np.array(model.predict(X_test))\n",
    "  preds = (np.where(probs[:,:] > threshold, 1, 0))\n",
    "  label = y_test\n",
    "  acc =clf_eval(preds,label)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19247fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 30) (150000, 15) (300000, 30) (300000, 15) (200000, 30) (200000, 15)\n",
      "Cj de Validacao:\n",
      "Accuracy: 58.68933333333334\n",
      "Accuracy 2 out: 25.168000000000003\n",
      "Accuracy 1 out: 55.903999999999996\n",
      "Accuracy 0 out: 94.99600000000001\n",
      "Accuracy: 84.03866666666666\n",
      "Accuracy 2 out: 67.228\n",
      "Accuracy 1 out: 89.89200000000001\n",
      "Accuracy 0 out: 94.99600000000001\n",
      "MSR: 59.548\n",
      "Cj de Teste:\n",
      "Accuracy: 76.88833333333334\n",
      "Accuracy 2 out: 25.052000000000003\n",
      "Accuracy 1 out: 56.276\n",
      "Accuracy 0 out: 95.0005\n",
      "Accuracy: 89.58966666666667\n",
      "Accuracy 2 out: 67.396\n",
      "Accuracy 1 out: 90.14\n",
      "Accuracy 0 out: 95.0005\n",
      "MSR: 59.71600000000001\n"
     ]
    }
   ],
   "source": [
    "# soh IDS ou L1\n",
    "#forma conjuntos de treino, Ev, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma); \n",
    "# valor máximo: 25,000\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "if alias=='gemael147' or alias=='ghi355gps':\n",
    "    #######train\n",
    "    aux36_train = (ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train)\n",
    "    obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "    label_36_train = outs_positions_36_train\n",
    "\n",
    "    aux69_train = (ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train)\n",
    "    obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "    label_69_train = outs_positions_69_train\n",
    "\n",
    "    #####teste\n",
    "    aux36 = (ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36)\n",
    "    X_test36 = np.concatenate(aux36,axis=1)\n",
    "    y_test36 = outs_positions_36\n",
    "\n",
    "    aux69 = (ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69)\n",
    "    X_test69 = np.concatenate(aux69,axis=1) \n",
    "    y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux=sum(np.transpose(y_test36))==0       \n",
    "X_Ev = X_test36[aux,:]\n",
    "y_Ev = y_test36[aux,:]\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+qtd_graphs,:],obs_36_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+qtd_graphs,:],label_36_train[50000:50000+qtd_graphs,:],\n",
    "                         label_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[50000:50000+qtd_graphs,:],\n",
    "                         label_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[25000:50000,:],obs_36_train[75000:100000,:],obs_36_train[125000:150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[25000:50000,:],obs_69_train[75000:100000,:],obs_69_train[125000:150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[25000:50000,:],label_36_train[75000:100000,:],label_36_train[125000:150000,:]),axis=0)\n",
    "y_val69 = np.concatenate((label_69_train[25000:50000,:],label_69_train[75000:100000,:],label_69_train[125000:150000,:]),axis=0)\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(qtd_graphs*VS),:],\n",
    "                          X_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(qtd_graphs*VS),:],\n",
    "                          X_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          X_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          X_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(qtd_graphs*VS),:],\n",
    "                          y_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(qtd_graphs*VS),:],\n",
    "                          y_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          y_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          y_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() #StandardScaler() #MinMaxScaler()\n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0)\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)\n",
    "\n",
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) #1234 \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "out3 = 0\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "print(\"Cj de Validacao:\") \n",
    "acc36 = fp_control(model, 0.05, X_val36, y_val36)\n",
    "acc69 = fp_control(model, 0.05, X_val69, y_val69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "print(\"Cj de Teste:\") \n",
    "acc36 = fp_control(model, 0.05, X_test36, y_test36)\n",
    "acc69 = fp_control(model, 0.05, X_test69, y_test69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "# soh IDS ou L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "809db5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 56) (150000, 14) (300000, 56) (300000, 14) (200000, 56) (200000, 14)\n",
      "Cj de Validacao:\n",
      "Accuracy: 62.562666666666665\n",
      "Accuracy 2 out: 32.300000000000004\n",
      "Accuracy 1 out: 60.616\n",
      "Accuracy 0 out: 94.772\n",
      "Accuracy: 91.48666666666668\n",
      "Accuracy 2 out: 85.104\n",
      "Accuracy 1 out: 94.584\n",
      "Accuracy 0 out: 94.772\n",
      "MSR: 68.151\n",
      "Cj de Teste:\n",
      "Accuracy: 78.74666666666667\n",
      "Accuracy 2 out: 31.836\n",
      "Accuracy 1 out: 60.641999999999996\n",
      "Accuracy 0 out: 95.0005\n",
      "Accuracy: 93.22500000000001\n",
      "Accuracy 2 out: 84.926\n",
      "Accuracy 1 out: 94.422\n",
      "Accuracy 0 out: 95.0005\n",
      "MSR: 67.95649999999999\n"
     ]
    }
   ],
   "source": [
    "# IDS, L1\n",
    "#forma conjuntos de treino, Ev, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma); \n",
    "# valor máximo: 25,000\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train,\n",
    "             ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train,\n",
    "             ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36,\n",
    "             ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69,\n",
    "             ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux=sum(np.transpose(y_test36))==0       \n",
    "X_Ev = X_test36[aux,:]\n",
    "y_Ev = y_test36[aux,:]\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+qtd_graphs,:],obs_36_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+qtd_graphs,:],label_36_train[50000:50000+qtd_graphs,:],\n",
    "                         label_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[50000:50000+qtd_graphs,:],\n",
    "                         label_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[25000:50000,:],obs_36_train[75000:100000,:],obs_36_train[125000:150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[25000:50000,:],obs_69_train[75000:100000,:],obs_69_train[125000:150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[25000:50000,:],label_36_train[75000:100000,:],label_36_train[125000:150000,:]),axis=0)\n",
    "y_val69 = np.concatenate((label_69_train[25000:50000,:],label_69_train[75000:100000,:],label_69_train[125000:150000,:]),axis=0)\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(qtd_graphs*VS),:],\n",
    "                          X_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(qtd_graphs*VS),:],\n",
    "                          X_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          X_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          X_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(qtd_graphs*VS),:],\n",
    "                          y_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(qtd_graphs*VS),:],\n",
    "                          y_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          y_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          y_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() #StandardScaler() #MinMaxScaler()\n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0)\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)\n",
    "\n",
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) #1234 \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "out3 = 0\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "print(\"Cj de Validacao:\") \n",
    "acc36 = fp_control(model, 0.05, X_val36, y_val36)\n",
    "acc69 = fp_control(model, 0.05, X_val69, y_val69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "print(\"Cj de Teste:\") \n",
    "acc36 = fp_control(model, 0.05, X_test36, y_test36)\n",
    "acc69 = fp_control(model, 0.05, X_test69, y_test69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "# IDS, L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dbd9da63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 84) (150000, 14) (300000, 84) (300000, 14) (200000, 84) (200000, 14)\n",
      "Cj de Validacao:\n",
      "Accuracy: 62.66533333333333\n",
      "Accuracy 2 out: 32.604\n",
      "Accuracy 1 out: 60.556\n",
      "Accuracy 0 out: 94.836\n",
      "Accuracy: 91.672\n",
      "Accuracy 2 out: 85.616\n",
      "Accuracy 1 out: 94.56400000000001\n",
      "Accuracy 0 out: 94.836\n",
      "MSR: 68.335\n",
      "Cj de Teste:\n",
      "Accuracy: 78.84066666666666\n",
      "Accuracy 2 out: 32.48\n",
      "Accuracy 1 out: 60.562000000000005\n",
      "Accuracy 0 out: 95.0005\n",
      "Accuracy: 93.28733333333334\n",
      "Accuracy 2 out: 85.394\n",
      "Accuracy 1 out: 94.328\n",
      "Accuracy 0 out: 95.0005\n",
      "MSR: 68.191\n"
     ]
    }
   ],
   "source": [
    "# IDS, L1, Linf1\n",
    "#forma conjuntos de treino, Ev, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma); \n",
    "# valor máximo: 25,000\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train,\n",
    "             ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train,\n",
    "             ypredELInf_pi_sig_obs_36_train,wAllELInf_pi_sig_obs_36_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train,\n",
    "             ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train,\n",
    "             ypredELInf_pi_sig_obs_69_train,wAllELInf_pi_sig_obs_69_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36,\n",
    "             ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36,\n",
    "             ypredELInf_pi_sig_obs_36,wAllELInf_pi_sig_obs_36)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69,\n",
    "             ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69,\n",
    "             ypredELInf_pi_sig_obs_69,wAllELInf_pi_sig_obs_69)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux=sum(np.transpose(y_test36))==0       \n",
    "X_Ev = X_test36[aux,:]\n",
    "y_Ev = y_test36[aux,:]\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+qtd_graphs,:],obs_36_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+qtd_graphs,:],label_36_train[50000:50000+qtd_graphs,:],\n",
    "                         label_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[50000:50000+qtd_graphs,:],\n",
    "                         label_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[25000:50000,:],obs_36_train[75000:100000,:],obs_36_train[125000:150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[25000:50000,:],obs_69_train[75000:100000,:],obs_69_train[125000:150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[25000:50000,:],label_36_train[75000:100000,:],label_36_train[125000:150000,:]),axis=0)\n",
    "y_val69 = np.concatenate((label_69_train[25000:50000,:],label_69_train[75000:100000,:],label_69_train[125000:150000,:]),axis=0)\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(qtd_graphs*VS),:],\n",
    "                          X_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(qtd_graphs*VS),:],\n",
    "                          X_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          X_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          X_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(qtd_graphs*VS),:],\n",
    "                          y_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(qtd_graphs*VS),:],\n",
    "                          y_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          y_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          y_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() #StandardScaler() #MinMaxScaler()\n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0)\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)\n",
    "\n",
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) #1234 \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "out3 = 0\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "print(\"Cj de Validacao:\") \n",
    "acc36 = fp_control(model, 0.05, X_val36, y_val36)\n",
    "acc69 = fp_control(model, 0.05, X_val69, y_val69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "print(\"Cj de Teste:\") \n",
    "acc36 = fp_control(model, 0.05, X_test36, y_test36)\n",
    "acc69 = fp_control(model, 0.05, X_test69, y_test69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "# IDS, L1, Linf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2e180be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 112) (150000, 14) (300000, 112) (300000, 14) (200000, 112) (200000, 14)\n",
      "Cj de Validacao:\n",
      "Accuracy: 63.22933333333334\n",
      "Accuracy 2 out: 34.472\n",
      "Accuracy 1 out: 60.431999999999995\n",
      "Accuracy 0 out: 94.784\n",
      "Accuracy: 91.71866666666666\n",
      "Accuracy 2 out: 86.47200000000001\n",
      "Accuracy 1 out: 93.89999999999999\n",
      "Accuracy 0 out: 94.784\n",
      "MSR: 68.81899999999999\n",
      "Cj de Teste:\n",
      "Accuracy: 79.13633333333333\n",
      "Accuracy 2 out: 34.27\n",
      "Accuracy 1 out: 60.546\n",
      "Accuracy 0 out: 95.0005\n",
      "Accuracy: 93.34666666666666\n",
      "Accuracy 2 out: 86.33\n",
      "Accuracy 1 out: 93.748\n",
      "Accuracy 0 out: 95.0005\n",
      "MSR: 68.7235\n"
     ]
    }
   ],
   "source": [
    "# IDS, L1, Linf1, Linf2\n",
    "#forma conjuntos de treino, Ev, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma); \n",
    "# valor máximo: 25,000\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train,\n",
    "             ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train,\n",
    "             ypredELInf_pi_sig_obs_36_train,wAllELInf_pi_sig_obs_36_train,ypredELInf_pp_sig_obs_36_train,wAllELInf_pp_sig_obs_36_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train,\n",
    "             ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train,\n",
    "             ypredELInf_pi_sig_obs_69_train,wAllELInf_pi_sig_obs_69_train,ypredELInf_pp_sig_obs_69_train,wAllELInf_pp_sig_obs_69_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36,\n",
    "             ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36,\n",
    "             ypredELInf_pi_sig_obs_36,wAllELInf_pi_sig_obs_36,ypredELInf_pp_sig_obs_36,wAllELInf_pp_sig_obs_36)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69,\n",
    "             ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69,\n",
    "             ypredELInf_pi_sig_obs_69,wAllELInf_pi_sig_obs_69,ypredELInf_pp_sig_obs_69,wAllELInf_pp_sig_obs_69)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux=sum(np.transpose(y_test36))==0       \n",
    "X_Ev = X_test36[aux,:]\n",
    "y_Ev = y_test36[aux,:]\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+qtd_graphs,:],obs_36_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+qtd_graphs,:],label_36_train[50000:50000+qtd_graphs,:],\n",
    "                         label_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[50000:50000+qtd_graphs,:],\n",
    "                         label_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[25000:50000,:],obs_36_train[75000:100000,:],obs_36_train[125000:150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[25000:50000,:],obs_69_train[75000:100000,:],obs_69_train[125000:150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[25000:50000,:],label_36_train[75000:100000,:],label_36_train[125000:150000,:]),axis=0)\n",
    "y_val69 = np.concatenate((label_69_train[25000:50000,:],label_69_train[75000:100000,:],label_69_train[125000:150000,:]),axis=0)\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(qtd_graphs*VS),:],\n",
    "                          X_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(qtd_graphs*VS),:],\n",
    "                          X_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          X_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          X_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(qtd_graphs*VS),:],\n",
    "                          y_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(qtd_graphs*VS),:],\n",
    "                          y_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          y_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          y_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() #StandardScaler() #MinMaxScaler()\n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0)\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)\n",
    "\n",
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) #1234 \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "out3 = 0\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "print(\"Cj de Validacao:\") \n",
    "acc36 = fp_control(model, 0.05, X_val36, y_val36)\n",
    "acc69 = fp_control(model, 0.05, X_val69, y_val69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "print(\"Cj de Teste:\") \n",
    "acc36 = fp_control(model, 0.05, X_test36, y_test36)\n",
    "acc69 = fp_control(model, 0.05, X_test69, y_test69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "# IDS, L1, Linf1, Linf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "66173246",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 383,
     "status": "ok",
     "timestamp": 1652121338793,
     "user": {
      "displayName": "STEFANO SURACI",
      "userId": "01042017575376796343"
     },
     "user_tz": 180
    },
    "id": "66173246",
    "outputId": "60f1f792-f77f-4ed4-c3dd-dab21b7a1aaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125000, 140) (150000, 14) (300000, 140) (300000, 14) (200000, 140) (200000, 14)\n",
      "Cj de Validacao:\n",
      "Accuracy: 63.33733333333333\n",
      "Accuracy 2 out: 34.855999999999995\n",
      "Accuracy 1 out: 60.343999999999994\n",
      "Accuracy 0 out: 94.812\n",
      "Accuracy: 91.69333333333334\n",
      "Accuracy 2 out: 86.58\n",
      "Accuracy 1 out: 93.688\n",
      "Accuracy 0 out: 94.812\n",
      "MSR: 68.86699999999999\n",
      "Cj de Teste:\n",
      "Accuracy: 79.18066666666667\n",
      "Accuracy 2 out: 34.583999999999996\n",
      "Accuracy 1 out: 60.498\n",
      "Accuracy 0 out: 95.0005\n",
      "Accuracy: 93.312\n",
      "Accuracy 2 out: 86.388\n",
      "Accuracy 1 out: 93.482\n",
      "Accuracy 0 out: 95.0005\n",
      "MSR: 68.738\n"
     ]
    }
   ],
   "source": [
    "# ALL base classifiers\n",
    "#forma conjuntos de treino, Ev, validacao e testes\n",
    "qtd_graphs = 25000 \n",
    "#qtd de MC cenários de redes geodésicas para cada qtd de outliers e intervalo de magnitude para o treinamento\n",
    "#a qtd de exemplos de treinamento vai ser isso x5, pois entra 0, 1 e 2 outs (sendo 1 e 2 outs para 3-6 e 6-9sigma); \n",
    "# valor máximo: 25,000\n",
    "\n",
    "\n",
    "#######train\n",
    "aux36_train = (ypredIDS_pp_36_train,wAllIDS_pp_36_train,\n",
    "             ypredEL1_pi_sigma_v_36_train,wAllEL1_pi_sigma_v_36_train,\n",
    "             ypredELInf_pi_sig_obs_36_train,wAllELInf_pi_sig_obs_36_train,ypredELInf_pp_sig_obs_36_train,wAllELInf_pp_sig_obs_36_train,\n",
    "             ypredSLRTMO_pp_36_train,wAllSLRTMO_pp_36_train)\n",
    "obs_36_train = np.concatenate(aux36_train,axis=1)\n",
    "label_36_train = outs_positions_36_train\n",
    "\n",
    "aux69_train = (ypredIDS_pp_69_train,wAllIDS_pp_69_train,\n",
    "             ypredEL1_pi_sigma_v_69_train,wAllEL1_pi_sigma_v_69_train,\n",
    "             ypredELInf_pi_sig_obs_69_train,wAllELInf_pi_sig_obs_69_train,ypredELInf_pp_sig_obs_69_train,wAllELInf_pp_sig_obs_69_train,\n",
    "             ypredSLRTMO_pp_69_train,wAllSLRTMO_pp_69_train)\n",
    "obs_69_train = np.concatenate(aux69_train,axis=1) \n",
    "label_69_train = outs_positions_69_train\n",
    "\n",
    "#####teste\n",
    "aux36 = (ypredIDS_pp_36,wAllIDS_pp_36,\n",
    "             ypredEL1_pi_sigma_v_36,wAllEL1_pi_sigma_v_36,\n",
    "             ypredELInf_pi_sig_obs_36,wAllELInf_pi_sig_obs_36,ypredELInf_pp_sig_obs_36,wAllELInf_pp_sig_obs_36,\n",
    "             ypredSLRTMO_pp_36,wAllSLRTMO_pp_36)\n",
    "X_test36 = np.concatenate(aux36,axis=1)\n",
    "y_test36 = outs_positions_36\n",
    "\n",
    "aux69 = (ypredIDS_pp_69,wAllIDS_pp_69,\n",
    "             ypredEL1_pi_sigma_v_69,wAllEL1_pi_sigma_v_69,\n",
    "             ypredELInf_pi_sig_obs_69,wAllELInf_pi_sig_obs_69,ypredELInf_pp_sig_obs_69,wAllELInf_pp_sig_obs_69,\n",
    "             ypredSLRTMO_pp_69,wAllSLRTMO_pp_69)\n",
    "X_test69 = np.concatenate(aux69,axis=1) \n",
    "y_test69 = outs_positions_69\n",
    "\n",
    "######Ev\n",
    "aux=sum(np.transpose(y_test36))==0       \n",
    "X_Ev = X_test36[aux,:]\n",
    "y_Ev = y_test36[aux,:]\n",
    "\n",
    "\n",
    "X_train36 = np.concatenate((obs_36_train[0:0+qtd_graphs,:],obs_36_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train36 = np.concatenate((label_36_train[0:0+qtd_graphs,:],label_36_train[50000:50000+qtd_graphs,:],\n",
    "                         label_36_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_train69 = np.concatenate((obs_69_train[50000:50000+qtd_graphs,:],\n",
    "                         obs_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "y_train69 = np.concatenate((label_69_train[50000:50000+qtd_graphs,:],\n",
    "                         label_69_train[100000:100000+int(qtd_graphs),:]),axis=0)\n",
    "X_val36 = np.concatenate((obs_36_train[25000:50000,:],obs_36_train[75000:100000,:],obs_36_train[125000:150000,:]),axis=0)\n",
    "X_val69 = np.concatenate((obs_69_train[25000:50000,:],obs_69_train[75000:100000,:],obs_69_train[125000:150000,:]),axis=0)\n",
    "y_val36 = np.concatenate((label_36_train[25000:50000,:],label_36_train[75000:100000,:],label_36_train[125000:150000,:]),axis=0)\n",
    "y_val69 = np.concatenate((label_69_train[25000:50000,:],label_69_train[75000:100000,:],label_69_train[125000:150000,:]),axis=0)\n",
    "\n",
    "\n",
    "VS = 0.8  ###### parte para treino\n",
    "X_train = np.concatenate((X_train36[0:int(qtd_graphs*VS),:],\n",
    "                          X_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          X_train69[0:int(qtd_graphs*VS),:],\n",
    "                          X_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          X_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          X_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          X_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          X_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "y_train = np.concatenate((y_train36[0:int(qtd_graphs*VS),:],\n",
    "                          y_train36[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*2):int(qtd_graphs*(2+VS)),:],\n",
    "                          y_train69[0:int(qtd_graphs*VS),:],\n",
    "                          y_train69[int(qtd_graphs*1):int(qtd_graphs*(1+VS)),:],\n",
    "                          y_train36[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train36[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:],\n",
    "                          y_train36[int(qtd_graphs*(2+VS)):int(qtd_graphs*3),:],\n",
    "                          y_train69[int(qtd_graphs*VS):int(qtd_graphs*1),:],\n",
    "                          y_train69[int(qtd_graphs*(1+VS)):int(qtd_graphs*2),:]),axis=0)\n",
    "\n",
    "scaler_train = MinMaxScaler() #StandardScaler() #MinMaxScaler()\n",
    "X_train = scaler_train.fit_transform(X_train)\n",
    "X_val36 = scaler_train.transform(X_val36)\n",
    "X_val69 = scaler_train.transform(X_val69)\n",
    "X_test36 = scaler_train.transform(X_test36)\n",
    "X_test69 = scaler_train.transform(X_test69)\n",
    "X_Ev = scaler_train.transform(X_Ev)\n",
    "\n",
    "X_val = np.concatenate((X_val36, X_val69),axis=0)\n",
    "y_val = np.concatenate((y_val36, y_val69),axis=0)\n",
    "X_test = np.concatenate((X_test36, X_test69),axis=0)\n",
    "y_test = np.concatenate((y_test36, y_test69),axis=0)\n",
    "\n",
    "\n",
    "print(X_train.shape,y_val.shape,X_test36.shape,y_test36.shape,X_Ev.shape,y_Ev.shape)\n",
    "\n",
    "#keras MLP \n",
    "hidden1 = math.ceil(X_train.shape[1]*(2/3))\n",
    "hidden2 = math.ceil(X_train.shape[1]*(1/3))\n",
    "\n",
    "# Create an early stopping callback.\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_acc\", min_delta=0.0001,patience=10, restore_best_weights=True)\n",
    "\n",
    "# define the keras model\n",
    "tf.random.set_seed(1234) #1234 \n",
    "#dropout_rate = 0.1\n",
    "model = Sequential()\n",
    "model.add(Dense(hidden1, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "model.add(Dense(hidden2, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(Dense(units=y_train.shape[1], activation='sigmoid'))   \n",
    "\n",
    "# compile the keras model\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss=keras.losses.BinaryCrossentropy(),\n",
    "              metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")])\n",
    "#model.summary()\n",
    "\n",
    "# fit the keras model on the dataset\n",
    "model.fit(X_train, y_train, epochs=200, batch_size=32,\n",
    "          verbose=0,callbacks=[early_stopping],validation_split=1-VS)\n",
    "\n",
    "out3 = 0\n",
    "#com mudança de valor critico para controlar taxa de FP:\n",
    "print(\"Cj de Validacao:\") \n",
    "acc36 = fp_control(model, 0.05, X_val36, y_val36)\n",
    "acc69 = fp_control(model, 0.05, X_val69, y_val69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "print(\"Cj de Teste:\") \n",
    "acc36 = fp_control(model, 0.05, X_test36, y_test36)\n",
    "acc69 = fp_control(model, 0.05, X_test69, y_test69)\n",
    "print(\"MSR:\", (acc36[0] + acc36[1] + acc69[0] + acc69[1])/4)\n",
    "# ALL"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "keras_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
